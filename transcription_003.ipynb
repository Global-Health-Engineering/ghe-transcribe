{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# To save your Huggingface token, run your terminal:\n",
    "# echo 'export HF_TOKEN=\"hf_*******************************\"' >> $HOME/.bashrc\n",
    "\n",
    "# Otherwise, the login function will prompt a login interface\n",
    "login(token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 14.50 SPEAKER_00  So welcome to this interview today. I'm sitting here with Natalie and we're going to have just a little interview with two questions. My name is Lars and I'm handing over to my interviewee to introduce yourself.\n",
      "14.50 21.00 SPEAKER_01  Okay, thank you. My name is Natalie. I'm an employee at GAG and we are testing this new device.\n",
      "21.00 29.00 SPEAKER_00  Okay, thank you. My first question to you is when is your next field trip?\n",
      "29.00 34.00 SPEAKER_01  That is a great question Lars. I am not sure. We are hoping for me.\n",
      "34.00 39.00 SPEAKER_00  Can you open for me? When was your last field trip?\n",
      "39.00 41.00 SPEAKER_01  I last went in July.\n",
      "41.00 44.00 SPEAKER_00  Okay, thank you very much for the interview.\n"
     ]
    }
   ],
   "source": [
    "# FROM https://github.com/yinruiqing/pyannote-whisper\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import utils # CREDIT: https://github.com/yinruiqing/pyannote-whisper\n",
    "import whisper\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize Pyannote pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\").to(device)\n",
    "\n",
    "# Load audio file\n",
    "audio_file = \"241118_1543.wav\"\n",
    "\n",
    "model = whisper.load_model(\"base.en\")\n",
    "asr_result = model.transcribe(audio_file)\n",
    "diarization_result = pipeline(audio_file)\n",
    "final_result = utils.diarize_text(asr_result, diarization_result)\n",
    "\n",
    "clear_output()\n",
    "for seg, spk, sent in final_result:\n",
    "    line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sent}'\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_transcribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
