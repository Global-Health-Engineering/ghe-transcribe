{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````sh\n",
    "pip3.12 install huggingface_hub pyannote.audio torch faster-whisper ipython ipykernel\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nmassari/ghe_local/venv_3.12_transcribe/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# To save your Huggingface token, run your terminal:\n",
    "# echo 'export HF_TOKEN=\"hf_*******************************\"' >> $HOME/.bashrc\n",
    "\n",
    "# Otherwise, the login function will prompt a login interface\n",
    "login(token=os.environ.get(\"HF_TOKEN\"))\n",
    "\n",
    "# FROM https://github.com/yinruiqing/pyannote-whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import utils # CREDIT: https://github.com/yinruiqing/pyannote-whisper\n",
    "from faster_whisper import WhisperModel\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "INFO:faster_whisper:Processing audio with duration 00:44.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 1.000000\n",
      "CPU times: user 43.1 s, sys: 6.79 s, total: 49.9 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize Pyannote pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\").to(device)\n",
    "\n",
    "# Load audio file\n",
    "audio_file = \"241118_1543.wav\"\n",
    "\n",
    "model = WhisperModel(\"medium.en\", device=\"cpu\", compute_type=\"float32\")\n",
    "segments, info = model.transcribe(audio_file, beam_size=5)\n",
    "generated_segments = list(segments)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "#for segment in segments:\n",
    "#    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to convert generated segments from faster_whisper to whisper format\n",
    "\n",
    "def to_whisper_format(generated_segments):\n",
    "    whisper_formatted_generated_segment = []\n",
    "    for segment in generated_segments:\n",
    "        whisper_formatted_generated_segment.append({\"id\":segment.id,\n",
    "                                                    \"seek\":segment.seek,\n",
    "                                                    \"start\":segment.start,\n",
    "                                                    \"end\":segment.end,\n",
    "                                                    \"text\":segment.text,\n",
    "                                                    \"tokens\":segment.tokens,\n",
    "                                                    \"avg_logprob\":segment.avg_logprob,\n",
    "                                                    \"compression_ratio\":segment.compression_ratio,\n",
    "                                                    \"no_speech_prob\":segment.no_speech_prob,\n",
    "                                                    \"words\":segment.words,\n",
    "                                                    \"temperature\":segment.temperature\n",
    "                                                   })\n",
    "    return {\"segments\": whisper_formatted_generated_segment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00;2.48;SPEAKER_00; So, welcome to this interview today.\n",
      "2.48;8.92;SPEAKER_00; I'm sitting here with Natalie, and we're going to have just a little interview with two questions.\n",
      "8.92;14.52;SPEAKER_00; My name is Lars, and I'm handing over to my interviewee to introduce herself.\n",
      "14.52;15.52;SPEAKER_01; Okay.\n",
      "15.52;16.52;SPEAKER_01; Thank you.\n",
      "16.52;17.52;SPEAKER_01; My name is Natalie.\n",
      "17.52;21.20;SPEAKER_01; I'm an employee at GAG, and we are testing this new device.\n",
      "21.20;24.56;SPEAKER_00; Okay, thank you.\n",
      "24.56;29.24;SPEAKER_00; My first question to you is, when is your next field trip?\n",
      "29.24;31.64;SPEAKER_01; That is a good question, Lars.\n",
      "31.64;32.64;SPEAKER_01; I'm not sure.\n",
      "32.64;34.28;SPEAKER_01; We're hoping for May.\n",
      "34.28;37.56;SPEAKER_00; Okay, you're hoping for May.\n",
      "37.56;39.02;SPEAKER_00; When was your last field trip?\n",
      "39.02;41.02;SPEAKER_01; I last went in July.\n",
      "41.02;43.32;SPEAKER_00; Okay, thank you very much for the interview.\n"
     ]
    }
   ],
   "source": [
    "diarization_result = pipeline(audio_file)\n",
    "result = utils.diarize_text(to_whisper_format(generated_segments), diarization_result)\n",
    "\n",
    "clear_output()\n",
    "for seg, spk, sentence in result:\n",
    "    print(f'{seg.start:.2f};{seg.end:.2f};{spk};{sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only available in VS code\n",
    "\n",
    "from IPython import get_ipython\n",
    "ip = get_ipython()\n",
    "path = None\n",
    "if '__vsc_ipynb_file__' in ip.user_ns:\n",
    "    path = ip.user_ns['__vsc_ipynb_file__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.write_to_txt(result, os.path.basename(path).removesuffix(\".ipynb\")+\".csv\", semicolumn=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3.12_transcribe",
   "language": "python",
   "name": "venv_3.12_transcribe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
